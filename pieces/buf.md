### 第一题 nlp做啥的主要研究内容
通过建立形式化计算模型来分析，理解和生成自然语言，其终极目标是让计算机拥有自然语言交际能力。主要问题有两个：自然语言理解和自然语言生成。其基本研究领域包括词法分析（汉语分词，词类标注，命名实体识别等等），句法分析，语义分析（词义标注，语义角色标注）等等。其应用领域包括机器翻译，文本摘要，人机对话，信息提取等等。

### 第二题 循环神经网络定义和它可以用来干啥
循环神经网络是一种面向序列结构的神经网络，在每个时刻t，RNN接受上一个时刻的隐状态和一个输入生成当前时刻的隐状态，其数学表示如下：blablabla......
循环神经网络是一个非常适合建模序列的神经网络，它具有很好的序列表达能力，可以将一个序列编码为深层的特征向量。它可以作为作为序列表示模型（应用于情感极性分类等任务），用最后一个时刻的隐层状态作为序列表示即可，也可以作为作为序列标注模型（应用于命名实体识别等任务），每个时刻的输出作为标注即可，还可以作为序列转写模型（应用于机器翻译等任务），依照encoder-decoder框架，将两个RNN串接，一个用作encoder一个用 decoder即可。

### 第三题 句法分析写句法树
。。。。。。

### 第四题 什么是数据稀疏怎么处理
由于训练样本不足而导致所估计的分布不可靠的问题，称为数据稀疏问题
以n元语言模型为例，若n元组在训练语料中没有出现，则该n元组的概率必定是0，最大似然估计给训练样本中为观察到的事件赋0概率，这显然是不合理的。
常用的解决方法有扩大语料规模和平滑，由于Zipf定律定律，语料库规模扩大，主要是高频词例的增加，扩大语料规模不能从根本上解决稀疏问题，所以主要的方法是平滑。
平滑就是把在训练样本中出现过的事件概率适当减小，把减小得到的概率质量分配给训练语料中没有出现过的事件。常用的平滑有加一平滑，Good-Truing平滑，katz平滑等等。

### 第五题 说pcfg的缺点并且举例
PCFG 没有考虑结构之间的依存关系。 PCFG 没有考虑词汇对句法结构的影响。
例子。。。。。。。

### 第六题 句子对齐的思路还有为啥不能用在词语对齐
主要包括基于长度的对齐方法和基于单词的对齐方法。
其依据：互为翻译的句子句长度高度相关，翻译时，句子顺序不做剧烈改变
词语对齐，词和译词的长度间不存在相关关系，翻译时，词序发生剧烈变化

### 第七题 lda原理说明还有概率话题模型的思路
不太会，lda大概是对pLSA的改进，是一种概率话题模型，文档视作话题的混合模型，话题视作词的不同分布，将贝叶斯估计的思想引入话题模型，是有向图模型。
概率话题模型的思路：文档是关于话题的分布，话题视作词的不同分布，文档看作是话题模型规定的随机过程的产物。通过最大似然估计的原则，最大化各个训练文档的概率。

### 第八题  em算法让你自己设计一个
不会
